%%% TABLES %%%%

\begin{table*}[t]
\caption{Allometric parameterisations and empirical parameter values employed in use case 2, adapted from \citet{Banas2011b}}
\begin{tabular}{l l l l l}
Empirical fit & Applicability & Source \\
\tophline
$\mu^i_{0} = (2.6 \ d^{-1}) \left( \frac{size^i_{P}}{1\mu m} \right)^{-0.45}$ & Phytoplankton 1-100 ESD \unit{\mu m} & Tang(1995) \\
$k^i_N = (0.1 \ \unit{\mu M \ N})\left( \frac{size^i_{P}}{1\mu m} \right)$ & Phytoplankton 1-100 ESD \unit{\mu m} & Eppley et al. (1969) \\

$I^j_0 = (26 \ d^{-1})\left( \frac{size^i_{P}}{1\mu m} \right)^{-0.4}$ & Flagellates, dinoflagellates, ciliates, copepods & Hansen et al. (1997) \\

$k^j_Z = 3 \ \unit{\mu M \ N} $ & Flagellates, dinoflagellates, ciliates, copepods & Hansen et al. (1997) \\

$size^j_{opt} = (0.65 \ \unit{\mu m})\left( \frac{size^i_{P}}{1\mu m} \right)^{0.56}$ & Flagellates, dinoflagellates, ciliates, copepods & Hansen et al. (1994) \\
$\Delta size_{P} = 0.25 $ & Ciliates, nauplii, copepodites & Hansen et al. (1994)  \\
\middlehline

\bottomhline
\end{tabular}
\belowtable{TODO: the sources need to be added properly! for now just text..} % Table Footnotes
\label{appendix:table:usecase2parameters}
\end{table*}




%%%%%


\subsubsection{Global nutrient, light and temperature climatologies as slab model forcing}
In line with the concept of phydra as a tool for rapid prototyping of marine ecosystem models, we compiled a set of global climatological forcings for slab models. These forcings are derived from World Ocean Atlas (WOA) 2018 data and a recent global MLD climatology kindly provided by Clément de Boyer Montégut, and Moderate Resolution Imaging Spectroradiometer (MODIS-aqua) satellite data for the time period 2002–2019.

WOA data provides objectively analysed climatological mean depth profiles of nutrients (nitrate, phosphate \& silicate) and temperature on 1 \unit{°} longitude/latitude grid \cite{Garcia2019WORLDSilicate}. The values have been interpolated from data collected in the World Ocean Database and provide an empirical estimate of the biogeochemical conditions in areas of the global ocean throughout the year. WOA 2018 data is maintained and provided by NOAA (\url{https://www.nodc.noaa.gov/OC5/woa18/woa18data.html, accessed October 2019}).\\

The MLD climatology is an updated version of the original climatology presented in  \citet{deBoyerMontegut2004MixedClimatology}, collecting data up until 2014 and with a modified criterion for MLD. The analysis of profile data combines a fixed threshold criterion for temperature (0.2 \unit{°C}) and a variable threshold criterion in density (equivalent to a 0.2 \unit{°C} decrease). MLD is diagnosed as the minimum calculated depth of both criterion for each station. This ensures that both temperature and salinity are homogeneous within the mixed layer, and compensated or barrier layers do not skew the values of MLD. This combined MLD criterion corresponds to a proxy of overturning extent depth over a few days, which lends this MLD value very well as the forcing that drives the upwelling of deeper nutrients into the upper mixed layer in slab physics (Clément de Boyer Montégut, personal communication). Spatial resolution of the climatology is on a 2 \unit{°} longitude/latitude grid.\\

In addition to the oceanographic and biogeochemical parameters, the provided set of global forcings includes a global climatology of irradiance from satellite data. The NASA satellite MODIS-aqua provides the most up-to-date global climatologies of photosynthetically active radiation (PAR) \cite{MODIS-Aqua2018NASAGroup}. 
\\
With this set of forcings we can experimentally run a slab model built in phydra in (almost) any location of the ocean. MLD can be used as an empirical forcing for mixing in our slab models. Average nutrient concentration below the mixed layer, extracted from the WOA 2018 climatologies, can be used to provide an estimate of nutrient supply at certain locations throughout the year. The deep nutrient climatology averages WOA 2018 data 5 \unit{m} below closest available climatological MLD value. The final 1 \unit{°} gridded data product can be accessed via Github [provide link] and is easily integrated with models built using the phydra package. 
The monthly climatologies are spatially averaged over a selected location (see Figure \ref{phydraforcing} a) and interpolated to obtain daily values (see Figure \ref{phydraforcing} b).






\subsection{Xarray-Simlab: object-oriented modelling framework}
%!
\textit{For now this subsection just includes my bullet points, Benoît Bovy has promised to write it.}
%!

A key point is in the name, xarray-simlab builds a flexible model structure on top xarray -> for labelled multidimensional datasets in python.

This means models in xarray-simlab natively use xarray as the basis for the data structure. A model with the proper parameterisation creates an xarray-dataset, which stores the output after model is run.

This 

- Further detail on the xarray-simlab framework used for phydra!

"xarray-simlab is a Python library that provides both a generic framework for building computational models in a modular fashion and a xarray extension for setting and running simulations using the xarray.Dataset structure. It is designed for fast, interactive and exploratory modelling."


specific version used here: v0.4.1 \cite{benoit_bovy_2020_3755979}


The xarray-simlab framework is built on a very few concepts that allow great flexibility in model customisation:

- models
- processes
- variables

\subsubsection{Models, processes and variables}
in xarray-simlab, (almost) everything is a process.
- in the following sections, introduce the specific implementation of xarray-simlab processes within phydra, what is actually implemented in v1 and how it can be modified and used.

models

processes

Just describe this in text...!

variables
- foreign variables
- group variables
- on-demand variables
- index variables
- object variables


\subsection{GEKKO Optimization suite: compiled solver back end}

Automatic differentiation provides the necessary gradients, accurate to machine precision, without extra work from the user.
that allows more efficient computation of larger models, a modular mathematical syntax from which to build our model,
and a powerful framework for model optimisation.


Model forcings and data used in model optimisation are represented by GEKKO parameters that are supplied to the model discretised at the same time-step that the model is solved.

The GEKKO package 

"GEKKO is an object-oriented Python library that offers model construction, analysis tools, and visualisation of simulation and optimisation."

"The GEKKO Python package solves large-scale mixed-integer and differential algebraic equations with nonlinear programming solvers. Modes of operation include machine learning, data reconciliation, real-time optimization, dynamic simulation, and nonlinear model predictive control." \cite{Beal2018GekkoSuite}

"GEKKO is not only an algebraic modeling language (AML) for posing optimization problems in simple object-oriented equation-based models to interface with powerful built-in optimization solvers but is also a package with the built-in ability to run model predictive control, dynamic parameter estimation, real-time optimization, and parameter update for dynamic models on real-time applications. The"

"Algebraic modeling languages (AML) facilitate the interface between advanced solvers and
human users. High-end, off-the-shelf gradient-based solvers require extensive information about the problem, including variable bounds, constraint functions and bounds, objective functions, and first and second derivatives of the functions, all in consistent array format. AMLs simplify the process by allowing the model to be written in a simple, intuitive format."

"GEKKO fills the role of a typical AML, but extends its capabilities to specialize in dynamic
optimization applications. As an AML, GEKKO provides a user-friendly, object-oriented Python interface to develop models and optimization solutions. Python is a free and open-source language that is flexible, popular, and powerful. IEEE Spectrum ranked Python the #1 programming language in 2017. Being a Python package allows GEKKO to easily interact with other popular scientific and numerical packages. Further, this enables GEKKO to connect to any real system that can be accessed through Python. Since Python is designed for readability and ease rather than speed, the Python GEKKO model is
converted to a low-level representation in the Fortran back-end for speed in function calls. Automatic differentiation provides the necessary gradients, accurate to machine precision, without extra work from the user. GEKKO then interacts with the built-in open-source, commercial, and custom large-scale solvers for linear, quadratic, nonlinear, and mixed integer programming (LP, QP, NLP, MILP, and MINLP) in the back-end. Optimization results are loaded back to Python for easy access and further analysis or manipulation."

specific version used here: v0.2.7

\subsubsection{Gekko variable types}
there are more, Gekko is much more complex than our use case, but the ones used in this implementation are
- Parameters. 
- Intermediates. 
- State Variables.  
- Equations.
additionally some functions like summing of terms (sum(x)) or calculating the Euler exponent (exp(x)) have specific implementations that are part of the Gekko library.




% FROM DIMENSIONALITY SECTION:
- Dimensionality is a very important fact of building models, and xarray-simlab provides a simple, but sometimes tricky interface for managing dimensionality, so make sure to explain it relatively well here, as well as the implementations.
- I can cite https://www.biogeosciences.net/17/609/2020/ to explain why dimensionality is an important consideration in phytoplankton models.